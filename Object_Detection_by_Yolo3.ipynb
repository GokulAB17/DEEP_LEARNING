{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "gpudl",
      "language": "python",
      "name": "gpudl"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "colab": {
      "name": "Object Detection_by_Yolo3.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehrSwx5s9DVR"
      },
      "source": [
        "# https://github.com/experiencor/keras-yolo3/blob/master/yolo3_one_file_to_detect_them_all.py\n",
        "import os\n",
        "import scipy.io\n",
        "import scipy.misc\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import PIL\n",
        "import struct\n",
        "import cv2\n",
        "from numpy import expand_dims\n",
        "import tensorflow as tf\n",
        "# from skimage.transform import resize\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.layers import Input, Lambda, Conv2D, BatchNormalization, LeakyReLU, ZeroPadding2D, UpSampling2D\n",
        "from tensorflow.keras.models import load_model, Model\n",
        "from tensorflow.keras.layers import add, concatenate\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from matplotlib import pyplot\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import imshow\n",
        "from matplotlib.patches import Rectangle\n",
        "%matplotlib inline"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cukoVSXv9DVy"
      },
      "source": [
        "class WeightReader:\n",
        "\tdef __init__(self, weight_file):\n",
        "\t\twith open(weight_file, 'rb') as w_f:\n",
        "\t\t\tmajor,\t= struct.unpack('i', w_f.read(4))\n",
        "\t\t\tminor,\t= struct.unpack('i', w_f.read(4))\n",
        "\t\t\trevision, = struct.unpack('i', w_f.read(4))\n",
        "\t\t\tif (major*10 + minor) >= 2 and major < 1000 and minor < 1000:\n",
        "\t\t\t\tw_f.read(8)\n",
        "\t\t\telse:\n",
        "\t\t\t\tw_f.read(4)\n",
        "\t\t\ttranspose = (major > 1000) or (minor > 1000)\n",
        "\t\t\tbinary = w_f.read()\n",
        "\t\tself.offset = 0\n",
        "\t\tself.all_weights = np.frombuffer(binary, dtype='float32')\n",
        " \n",
        "\tdef read_bytes(self, size):\n",
        "\t\tself.offset = self.offset + size\n",
        "\t\treturn self.all_weights[self.offset-size:self.offset]\n",
        " \n",
        "\tdef load_weights(self, model):\n",
        "\t\tfor i in range(106):\n",
        "\t\t\ttry:\n",
        "\t\t\t\tconv_layer = model.get_layer('conv_' + str(i))\n",
        "\t\t\t\tprint(\"loading weights of convolution #\" + str(i))\n",
        "\t\t\t\tif i not in [81, 93, 105]:\n",
        "\t\t\t\t\tnorm_layer = model.get_layer('bnorm_' + str(i))\n",
        "\t\t\t\t\tsize = np.prod(norm_layer.get_weights()[0].shape)\n",
        "\t\t\t\t\tbeta  = self.read_bytes(size) # bias\n",
        "\t\t\t\t\tgamma = self.read_bytes(size) # scale\n",
        "\t\t\t\t\tmean  = self.read_bytes(size) # mean\n",
        "\t\t\t\t\tvar   = self.read_bytes(size) # variance\n",
        "\t\t\t\t\tweights = norm_layer.set_weights([gamma, beta, mean, var])\n",
        "\t\t\t\tif len(conv_layer.get_weights()) > 1:\n",
        "\t\t\t\t\tbias   = self.read_bytes(np.prod(conv_layer.get_weights()[1].shape))\n",
        "\t\t\t\t\tkernel = self.read_bytes(np.prod(conv_layer.get_weights()[0].shape))\n",
        "\t\t\t\t\tkernel = kernel.reshape(list(reversed(conv_layer.get_weights()[0].shape)))\n",
        "\t\t\t\t\tkernel = kernel.transpose([2,3,1,0])\n",
        "\t\t\t\t\tconv_layer.set_weights([kernel, bias])\n",
        "\t\t\t\telse:\n",
        "\t\t\t\t\tkernel = self.read_bytes(np.prod(conv_layer.get_weights()[0].shape))\n",
        "\t\t\t\t\tkernel = kernel.reshape(list(reversed(conv_layer.get_weights()[0].shape)))\n",
        "\t\t\t\t\tkernel = kernel.transpose([2,3,1,0])\n",
        "\t\t\t\t\tconv_layer.set_weights([kernel])\n",
        "\t\t\texcept ValueError:\n",
        "\t\t\t\tprint(\"no convolution #\" + str(i))\n",
        " \n",
        "\tdef reset(self):\n",
        "\t\tself.offset = 0"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJqHm9Hk9DV2"
      },
      "source": [
        "def _conv_block(inp, convs, skip=True):\n",
        "\tx = inp\n",
        "\tcount = 0\n",
        "\tfor conv in convs:\n",
        "\t\tif count == (len(convs) - 2) and skip:\n",
        "\t\t\tskip_connection = x\n",
        "\t\tcount += 1\n",
        "\t\tif conv['stride'] > 1: x = ZeroPadding2D(((1,0),(1,0)))(x) # peculiar padding as darknet prefer left and top\n",
        "\t\tx = Conv2D(conv['filter'],\n",
        "\t\t\t\t   conv['kernel'],\n",
        "\t\t\t\t   strides=conv['stride'],\n",
        "\t\t\t\t   padding='valid' if conv['stride'] > 1 else 'same', # peculiar padding as darknet prefer left and top\n",
        "\t\t\t\t   name='conv_' + str(conv['layer_idx']),\n",
        "\t\t\t\t   use_bias=False if conv['bnorm'] else True)(x)\n",
        "\t\tif conv['bnorm']: x = BatchNormalization(epsilon=0.001, name='bnorm_' + str(conv['layer_idx']))(x)\n",
        "\t\tif conv['leaky']: x = LeakyReLU(alpha=0.1, name='leaky_' + str(conv['layer_idx']))(x)\n",
        "\treturn add([skip_connection, x]) if skip else x\n",
        "\n",
        "def make_yolov3_model():\n",
        "\tinput_image = Input(shape=(None, None, 3))\n",
        "\t# Layer  0 => 4\n",
        "\tx = _conv_block(input_image, [{'filter': 32, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 0},\n",
        "\t\t\t\t\t\t\t\t  {'filter': 64, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 1},\n",
        "\t\t\t\t\t\t\t\t  {'filter': 32, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 2},\n",
        "\t\t\t\t\t\t\t\t  {'filter': 64, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 3}])\n",
        "\t# Layer  5 => 8\n",
        "\tx = _conv_block(x, [{'filter': 128, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 5},\n",
        "\t\t\t\t\t\t{'filter':  64, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 6},\n",
        "\t\t\t\t\t\t{'filter': 128, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 7}])\n",
        "\t# Layer  9 => 11\n",
        "\tx = _conv_block(x, [{'filter':  64, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 9},\n",
        "\t\t\t\t\t\t{'filter': 128, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 10}])\n",
        "\t# Layer 12 => 15\n",
        "\tx = _conv_block(x, [{'filter': 256, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 12},\n",
        "\t\t\t\t\t\t{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 13},\n",
        "\t\t\t\t\t\t{'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 14}])\n",
        "\t# Layer 16 => 36\n",
        "\tfor i in range(7):\n",
        "\t\tx = _conv_block(x, [{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 16+i*3},\n",
        "\t\t\t\t\t\t\t{'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 17+i*3}])\n",
        "\tskip_36 = x\n",
        "\t# Layer 37 => 40\n",
        "\tx = _conv_block(x, [{'filter': 512, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 37},\n",
        "\t\t\t\t\t\t{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 38},\n",
        "\t\t\t\t\t\t{'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 39}])\n",
        "\t# Layer 41 => 61\n",
        "\tfor i in range(7):\n",
        "\t\tx = _conv_block(x, [{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 41+i*3},\n",
        "\t\t\t\t\t\t\t{'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 42+i*3}])\n",
        "\tskip_61 = x\n",
        "\t# Layer 62 => 65\n",
        "\tx = _conv_block(x, [{'filter': 1024, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 62},\n",
        "\t\t\t\t\t\t{'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 63},\n",
        "\t\t\t\t\t\t{'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 64}])\n",
        "\t# Layer 66 => 74\n",
        "\tfor i in range(3):\n",
        "\t\tx = _conv_block(x, [{'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 66+i*3},\n",
        "\t\t\t\t\t\t\t{'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 67+i*3}])\n",
        "\t# Layer 75 => 79\n",
        "\tx = _conv_block(x, [{'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 75},\n",
        "\t\t\t\t\t\t{'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 76},\n",
        "\t\t\t\t\t\t{'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 77},\n",
        "\t\t\t\t\t\t{'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 78},\n",
        "\t\t\t\t\t\t{'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 79}], skip=False)\n",
        "\t# Layer 80 => 82\n",
        "\tyolo_82 = _conv_block(x, [{'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 80},\n",
        "\t\t\t\t\t\t\t  {'filter':  255, 'kernel': 1, 'stride': 1, 'bnorm': False, 'leaky': False, 'layer_idx': 81}], skip=False)\n",
        "\t# Layer 83 => 86\n",
        "\tx = _conv_block(x, [{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 84}], skip=False)\n",
        "\tx = UpSampling2D(2)(x)\n",
        "\tx = concatenate([x, skip_61])\n",
        "\t# Layer 87 => 91\n",
        "\tx = _conv_block(x, [{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 87},\n",
        "\t\t\t\t\t\t{'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 88},\n",
        "\t\t\t\t\t\t{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 89},\n",
        "\t\t\t\t\t\t{'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 90},\n",
        "\t\t\t\t\t\t{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 91}], skip=False)\n",
        "\t# Layer 92 => 94\n",
        "\tyolo_94 = _conv_block(x, [{'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 92},\n",
        "\t\t\t\t\t\t\t  {'filter': 255, 'kernel': 1, 'stride': 1, 'bnorm': False, 'leaky': False, 'layer_idx': 93}], skip=False)\n",
        "\t# Layer 95 => 98\n",
        "\tx = _conv_block(x, [{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True,   'layer_idx': 96}], skip=False)\n",
        "\tx = UpSampling2D(2)(x)\n",
        "\tx = concatenate([x, skip_36])\n",
        "\t# Layer 99 => 106\n",
        "\tyolo_106 = _conv_block(x, [{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 99},\n",
        "\t\t\t\t\t\t\t   {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 100},\n",
        "\t\t\t\t\t\t\t   {'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 101},\n",
        "\t\t\t\t\t\t\t   {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 102},\n",
        "\t\t\t\t\t\t\t   {'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 103},\n",
        "\t\t\t\t\t\t\t   {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 104},\n",
        "\t\t\t\t\t\t\t   {'filter': 255, 'kernel': 1, 'stride': 1, 'bnorm': False, 'leaky': False, 'layer_idx': 105}], skip=False)\n",
        "\tmodel = Model(input_image, [yolo_82, yolo_94, yolo_106])\n",
        "\treturn model"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "ADtWzRR99DWG",
        "outputId": "2dc984a0-7be9-4e94-ccec-272735a2d469"
      },
      "source": [
        "# define the yolo v3 model\n",
        "yolov3 = make_yolov3_model()\n",
        "\n",
        "# load the weights\n",
        "weight_reader = WeightReader('../data/yolov3.weights')\n",
        "\n",
        "# set the weights\n",
        "weight_reader.load_weights(yolov3)\n",
        "\n",
        "# save the model to file\n",
        "yolov3.save('model.h5')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-68cb594c6b0b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# load the weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mweight_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWeightReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../data/yolov3.weights'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# set the weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-45b6a7484a09>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, weight_file)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mWeightReader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                 \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mw_f\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m                         \u001b[0mmajor\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                         \u001b[0mminor\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/yolov3.weights'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pY88m3ra9DWW"
      },
      "source": [
        "class BoundBox:\n",
        "    def __init__(self, xmin, ymin, xmax, ymax, objness = None, classes = None):\n",
        "        self.xmin = xmin\n",
        "        self.ymin = ymin\n",
        "        self.xmax = xmax\n",
        "        self.ymax = ymax\n",
        "        self.objness = objness\n",
        "        self.classes = classes\n",
        "        self.label = -1\n",
        "        self.score = -1\n",
        "    \n",
        "    def get_label(self):\n",
        "        if self.label == -1:\n",
        "            self.label = np.argmax(self.classes)\n",
        "\n",
        "        return self.label\n",
        "  \n",
        "    def get_score(self):\n",
        "        if self.score == -1:\n",
        "            self.score = self.classes[self.get_label()]\n",
        "        return self.get_score\n",
        "\n",
        "def _sigmoid(x):\n",
        "    return 1. /(1. + np.exp(-x))\n",
        "\n",
        "def decode_netout(netout, anchors, obj_thresh, net_h, net_w):\n",
        "\tgrid_h, grid_w = netout.shape[:2]\n",
        "\tnb_box = 3\n",
        "\tnetout = netout.reshape((grid_h, grid_w, nb_box, -1))\n",
        "\tnb_class = netout.shape[-1] - 5\n",
        "\tboxes = []\n",
        "\tnetout[..., :2]  = _sigmoid(netout[..., :2])\n",
        "\tnetout[..., 4:]  = _sigmoid(netout[..., 4:])\n",
        "\tnetout[..., 5:]  = netout[..., 4][..., np.newaxis] * netout[..., 5:]\n",
        "\tnetout[..., 5:] *= netout[..., 5:] > obj_thresh\n",
        " \n",
        "\tfor i in range(grid_h*grid_w):\n",
        "\t\trow = i / grid_w\n",
        "\t\tcol = i % grid_w\n",
        "\t\tfor b in range(nb_box):\n",
        "\t\t\t# 4th element is objectness score\n",
        "\t\t\tobjectness = netout[int(row)][int(col)][b][4]\n",
        "\t\t\tif(objectness.all() <= obj_thresh): continue\n",
        "\t\t\t# first 4 elements are x, y, w, and h\n",
        "\t\t\tx, y, w, h = netout[int(row)][int(col)][b][:4]\n",
        "\t\t\tx = (col + x) / grid_w # center position, unit: image width\n",
        "\t\t\ty = (row + y) / grid_h # center position, unit: image height\n",
        "\t\t\tw = anchors[2 * b + 0] * np.exp(w) / net_w # unit: image width\n",
        "\t\t\th = anchors[2 * b + 1] * np.exp(h) / net_h # unit: image height\n",
        "\t\t\t# last elements are class probabilities\n",
        "\t\t\tclasses = netout[int(row)][col][b][5:]\n",
        "\t\t\tbox = BoundBox(x-w/2, y-h/2, x+w/2, y+h/2, objectness, classes)\n",
        "\t\t\tboxes.append(box)\n",
        "\treturn boxes"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J0ye4SIr9DWY"
      },
      "source": [
        "def correct_yolo_boxes(boxes, image_h, image_w, net_h, net_w):\n",
        "\tnew_w, new_h = net_w, net_h\n",
        "\tfor i in range(len(boxes)):\n",
        "\t\tx_offset, x_scale = (net_w - new_w)/2./net_w, float(new_w)/net_w\n",
        "\t\ty_offset, y_scale = (net_h - new_h)/2./net_h, float(new_h)/net_h\n",
        "\t\tboxes[i].xmin = int((boxes[i].xmin - x_offset) / x_scale * image_w)\n",
        "\t\tboxes[i].xmax = int((boxes[i].xmax - x_offset) / x_scale * image_w)\n",
        "\t\tboxes[i].ymin = int((boxes[i].ymin - y_offset) / y_scale * image_h)\n",
        "\t\tboxes[i].ymax = int((boxes[i].ymax - y_offset) / y_scale * image_h)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NmRyaSvH9DWZ"
      },
      "source": [
        "def _interval_overlap(interval_a, interval_b):\n",
        "\tx1, x2 = interval_a\n",
        "\tx3, x4 = interval_b\n",
        "\tif x3 < x1:\n",
        "\t\tif x4 < x1:\n",
        "\t\t\treturn 0\n",
        "\t\telse:\n",
        "\t\t\treturn min(x2,x4) - x1\n",
        "\telse:\n",
        "\t\tif x2 < x3:\n",
        "\t\t\t return 0\n",
        "\t\telse:\n",
        "\t\t\treturn min(x2,x4) - x3\n",
        "\n",
        "def bbox_iou(box1, box2):\n",
        "    intersect_w = _interval_overlap([box1.xmin, box1.xmax], [box2.xmin, box2.xmax])\n",
        "    intersect_h = _interval_overlap([box1.ymin, box1.ymax], [box2.ymin, box2.ymax])\n",
        "    intersect = intersect_w * intersect_h\n",
        "    w1, h1 = box1.xmax-box1.xmin, box1.ymax-box1.ymin\n",
        "    w2, h2 = box2.xmax-box2.xmin, box2.ymax-box2.ymin\n",
        "    union = w1*h1 + w2*h2 - intersect\n",
        "    return float(intersect) / union\n",
        " \n",
        "def do_nms(boxes, nms_thresh):\n",
        "\tif len(boxes) > 0:\n",
        "\t\tnb_class = len(boxes[0].classes)\n",
        "\telse:\n",
        "\t\treturn\n",
        "\tfor c in range(nb_class):\n",
        "\t\tsorted_indices = np.argsort([-box.classes[c] for box in boxes])\n",
        "\t\tfor i in range(len(sorted_indices)):\n",
        "\t\t\tindex_i = sorted_indices[i]\n",
        "\t\t\tif boxes[index_i].classes[c] == 0: continue\n",
        "\t\t\tfor j in range(i+1, len(sorted_indices)):\n",
        "\t\t\t\tindex_j = sorted_indices[j]\n",
        "\t\t\t\tif bbox_iou(boxes[index_i], boxes[index_j]) >= nms_thresh:\n",
        "\t\t\t\t\tboxes[index_j].classes[c] = 0\n",
        "\n",
        "# get all of the results above a threshold\n",
        "def get_boxes(boxes, labels, thresh):\n",
        "\tv_boxes, v_labels, v_scores = list(), list(), list()\n",
        "\t# enumerate all boxes\n",
        "\tfor box in boxes:\n",
        "\t\t# enumerate all possible labels\n",
        "\t\tfor i in range(len(labels)):\n",
        "\t\t\t# check if the threshold for this label is high enough\n",
        "\t\t\tif box.classes[i] > thresh:\n",
        "\t\t\t\tv_boxes.append(box)\n",
        "\t\t\t\tv_labels.append(labels[i])\n",
        "\t\t\t\tv_scores.append(box.classes[i]*100)\n",
        "\t\t\t\t# don't break, many labels may trigger for one box\n",
        "\treturn v_boxes, v_labels, v_scores\n",
        "\n",
        "# draw all results\n",
        "def draw_boxes(filename, v_boxes, v_labels, v_scores):\n",
        "  \n",
        "\t# load the image\n",
        "\tdata = pyplot.imread(filename)\n",
        "\t# plot the image\n",
        "\tpyplot.imshow(data)\n",
        "\t# get the context for drawing boxes\n",
        "\tax = pyplot.gca()\n",
        "\t# plot each box\n",
        "\tfor i in range(len(v_boxes)):\n",
        "\t\tbox = v_boxes[i]\n",
        "\t\t# get coordinates\n",
        "\t\ty1, x1, y2, x2 = box.ymin, box.xmin, box.ymax, box.xmax\n",
        "\t\t# calculate width and height of the box\n",
        "\t\twidth, height = x2 - x1, y2 - y1\n",
        "\t\t# create the shape\n",
        "\t\trect = Rectangle((x1, y1), width, height, fill=False, color='yellow', linewidth = '2')\n",
        "\t\t# draw the box\n",
        "\t\tax.add_patch(rect)\n",
        "\t\t# draw text and score in top left corner\n",
        "\t\tlabel = \"%s (%.3f)\" % (v_labels[i], v_scores[i])\n",
        "\t\tpyplot.text(x1, y1, label, color='yellow')\n",
        "\t# show the plot\n",
        "\tpyplot.show()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6yzd8NjS9DWa"
      },
      "source": [
        "# define the anchors\n",
        "anchors = [[116,90, 156,198, 373,326], [30,61, 62,45, 59,119], [10,13, 16,30, 33,23]]\n",
        "\n",
        "# define the probability threshold for detected objects\n",
        "class_threshold = 0.6\n",
        "\n",
        "# define the labels\n",
        "labels = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\",\n",
        "\t\"boat\", \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\",\n",
        "\t\"bird\", \"cat\", \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\",\n",
        "\t\"backpack\", \"umbrella\", \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\",\n",
        "\t\"sports ball\", \"kite\", \"baseball bat\", \"baseball glove\", \"skateboard\", \"surfboard\",\n",
        "\t\"tennis racket\", \"bottle\", \"wine glass\", \"cup\", \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\",\n",
        "\t\"apple\", \"sandwich\", \"orange\", \"broccoli\", \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\",\n",
        "\t\"chair\", \"sofa\", \"pottedplant\", \"bed\", \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\",\n",
        "\t\"remote\", \"keyboard\", \"cell phone\", \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\",\n",
        "\t\"book\", \"clock\", \"vase\", \"scissors\", \"teddy bear\", \"hair drier\", \"toothbrush\"]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6eDn68A29DWb"
      },
      "source": [
        "\n",
        "def load_image_pixels(filename, shape):\n",
        "  # load image to get its shape\n",
        "    image = load_img(filename)\n",
        "    width, height = image.size\n",
        "    \n",
        "    # Conversion to 416*416 & Numpy Array\n",
        "    image = load_img(filename, target_size=shape)\n",
        "    image = img_to_array(image)\n",
        "\n",
        "    # grayscale image normalization\n",
        "    image = image.astype('float32')\n",
        "    #Explore division of int by float\n",
        "    image /= 255.0\n",
        "\n",
        "    # add a dimension so that we have one sample \n",
        "    # Check Numpy library for expand dims \n",
        "    image = expand_dims(image, 0)\n",
        "    return image, width, height"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFsMUshQ9DWb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zn9YjRaZ9DWc"
      },
      "source": [
        "def predict_and_draw(file_path):\n",
        "    # define the expected input shape for the model\n",
        "    input_w, input_h = 416, 416\n",
        "\n",
        "    image, image_w, image_h = load_image_pixels(file_path, (input_w, input_h))\n",
        "\n",
        "    # make prediction\n",
        "    yhat = yolov3.predict(image)\n",
        "    # summarize the shape of the list of arrays\n",
        "    # print([a.shape for a in yhat])\n",
        "    # # input()\n",
        "\n",
        "    boxes = list() \n",
        "    for i in range(len(yhat)):\n",
        "        # decode the output of the network\n",
        "        boxes += decode_netout(yhat[i][0], anchors[i], class_threshold, input_h, input_w)\n",
        "\n",
        "    # correct the sizes of the bounding boxes for the shape of the image\n",
        "    correct_yolo_boxes(boxes, image_h, image_w, input_h, input_w)\n",
        "\n",
        "    # suppress non-maximal boxes\n",
        "    do_nms(boxes, 0.5)\n",
        "\n",
        "    \"\"\"\n",
        "    Commits till do_nms:\n",
        "        Loaded the image\n",
        "        Tranformed the image\n",
        "        predicted the bounding boxes\n",
        "        Correction of Bounding box according to original image dimension\n",
        "        Perform Non - Max Suppression\n",
        "    \"\"\"\n",
        "\n",
        "    # get the details of the detected objects\n",
        "    v_boxes, v_labels, v_scores = get_boxes(boxes, labels, class_threshold)\n",
        "\n",
        "    # summarize what we found\n",
        "    for i in range(len(v_boxes)):\n",
        "        print(v_labels[i], v_scores[i])\n",
        "\n",
        "    # draw what we found\n",
        "    draw_boxes(file_path, v_boxes, v_labels, v_scores)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "id": "ATnDYweR9DWd",
        "outputId": "48bd90f4-65b7-4686-fb81-f2599a1f5086"
      },
      "source": [
        "predict_and_draw(\"../evaluation/random_3.jpeg\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-0945681197d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredict_and_draw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../evaluation/random_3.jpeg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-11-60b92de65dd3>\u001b[0m in \u001b[0;36mpredict_and_draw\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0minput_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_h\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m416\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m416\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_h\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_image_pixels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_h\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# make prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-e7de789616b8>\u001b[0m in \u001b[0;36mload_image_pixels\u001b[0;34m(filename, shape)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_image_pixels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0;31m# load image to get its shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/preprocessing/image.py\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, color_mode, target_size, interpolation)\u001b[0m\n\u001b[1;32m    298\u001b[0m   \"\"\"\n\u001b[1;32m    299\u001b[0m   return image.load_img(path, grayscale=grayscale, color_mode=color_mode,\n\u001b[0;32m--> 300\u001b[0;31m                         target_size=target_size, interpolation=interpolation)\n\u001b[0m\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/utils.py\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, color_mode, target_size, interpolation)\u001b[0m\n\u001b[1;32m    111\u001b[0m         raise ImportError('Could not import PIL.Image. '\n\u001b[1;32m    112\u001b[0m                           'The use of `load_img` requires PIL.')\n\u001b[0;32m--> 113\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcolor_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'grayscale'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../evaluation/random_3.jpeg'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmiaUfKk9DWe"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LlNkAyAC9DWf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}